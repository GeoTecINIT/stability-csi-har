{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43dcbf6d-a190-4418-be8e-ec7e9df15075",
   "metadata": {},
   "source": [
    "# Evaluation on public dataset: Multi environment\n",
    "\n",
    "This notebook uses the multi environment dataset to evaluate a preprocessing pipeline and a CNN-based classification model. This dataset was described in:\n",
    "\n",
    "> Bahaâ€™A, A., Almazari, M. M., Alazrai, R., & Daoud, M. I. (2020). A dataset for Wi-Fi-based human activity recognition in line-of-sight and non-line-of-sight indoor environments. Data in Brief, 33, 106534.\n",
    "\n",
    "The dataset contains data from three different environments, i.e., E1, E2 and E3. However, only E1 and E2 will be used (since they are line-of-sight).\n",
    "The results obtained from the evaluation on both datasets are stored in `02_RESULTS/02_MULTI-ENV/01_MODEL-REPORTS/` and can be loaded in the [Section 1.6](#summary-multi) of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4615d1-6df5-407a-bf3c-2e638cb6acdc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6b59dd-2a43-4458-9239-ae267c840163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from alive_progress import alive_bar\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from functions.filters import dbscan_filtering, wavelet_filtering\n",
    "from functions.json import load_json, save_json\n",
    "from functions.ml import clear_backend_and_seeds, cross_validation, one_hot_encoding\n",
    "from functions.report_metrics import metrics_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c093089-c9ad-4064-b778-4a445f8f8039",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea4ae2f-7730-4a00-ba73-9fcecfde3848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA = os.path.join('01_DATA', '02_MULTI-ENV')\n",
    "ENV1 = os.path.join(DATA, 'ENVIRONMENT 1')\n",
    "ENV2 = os.path.join(DATA, 'ENVIRONMENT 2')\n",
    "\n",
    "RESULTS = '02_RESULTS'\n",
    "\n",
    "MULTI_ENV_REPORTS = os.path.join(RESULTS, '02_MULTI-ENV', '01_MODEL-REPORTS', '{0}-reports.json')\n",
    "MULTI_ENV_LABELS = ['No movement', 'Falling', 'Walking', 'Sitting/Standing', 'Turning', 'Pick up pen']\n",
    "\n",
    "ACTIVITY_MAPPING = {\n",
    "    'A01': 'A1',\n",
    "    'A02': 'A2',\n",
    "    'A03': 'A1',\n",
    "    'A04': 'A1',\n",
    "    'A05': 'A2',\n",
    "    'A06': 'A3',\n",
    "    'A07': 'A5',\n",
    "    'A08': 'A3',\n",
    "    'A09': 'A5',\n",
    "    'A10': 'A4',\n",
    "    'A11': 'A4',\n",
    "    'A12': 'A6',\n",
    "}\n",
    "\n",
    "MAPPING = {'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4, 'A6': 5}\n",
    "NUM_CLASSES = len(MULTI_ENV_LABELS)\n",
    "\n",
    "FOLDS = 10\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb44047d-6682-4c03-befb-c4695f470720",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10f77f-564d-4b38-924e-aa1d13771c6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753562e-caaf-40b3-afdb-0635fffbc7b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(environment):\n",
    "    data = {}\n",
    "    subject_dirs = os.listdir(environment)\n",
    "    subject_dirs = list(filter(lambda x: x.startswith('Subject'), subject_dirs))\n",
    "    with alive_bar(len(subject_dirs), title=f'Loading data from subjects', force_tty=True) as progress_bar:\n",
    "        for subject_dir in subject_dirs:\n",
    "            dfs = []\n",
    "            subject = f'S{int(subject_dir.split(\" \")[-1]):02d}'\n",
    "            data[subject] = {}\n",
    "            subject_dir_path = os.path.join(environment, subject_dir)\n",
    "            for file in os.listdir(subject_dir_path):\n",
    "                if not file.endswith('.csv'):\n",
    "                    continue\n",
    "\n",
    "                base_activity = file.split('_')[3]\n",
    "                file_path = os.path.join(subject_dir_path, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                df = df.iloc[160:-160] #remove 0.5 sec after and before due to noise\n",
    "\n",
    "                if base_activity not in data[subject]:\n",
    "                    data[subject][base_activity] = df\n",
    "                else:\n",
    "                    data[subject][base_activity] = pd.concat([data[subject][base_activity], df])\n",
    "            progress_bar()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c0d32-491e-4f06-b1cf-13f6d75fd518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def amplitude_from_raw_data(data):\n",
    "    amplitudes = {}\n",
    "    with alive_bar(len(data.keys()), title=f'Extracting amplitudes from subject\\'s data', force_tty=True) as progress_bar:\n",
    "        for subject in data:\n",
    "            amplitudes[subject] = {}\n",
    "            for activity in data[subject]:\n",
    "                activity_data = data[subject][activity]\n",
    "                activity_amplitudes = []\n",
    "                for index, row in activity_data.iterrows():\n",
    "                    instance_amplitudes = []\n",
    "                    for antenna in range(1,4):\n",
    "                        for subcarrier in range(1,31):\n",
    "                            csi_data = row[f'csi_1_{antenna}_{subcarrier}']\n",
    "                            real, imaginary = csi_data.split('+')\n",
    "                            real = int(real)\n",
    "                            imaginary = int(imaginary[:-1])\n",
    "\n",
    "                            instance_amplitudes.append(sqrt(imaginary ** 2 + real ** 2))\n",
    "                    activity_amplitudes.append(instance_amplitudes)\n",
    "                amplitudes[subject][activity] = np.array(activity_amplitudes)\n",
    "            progress_bar()\n",
    "    return amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663f66d-2e8c-4b58-bc64-64eb3ec0b1f5",
   "metadata": {},
   "source": [
    "### Data windowing and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8eff4-9cfb-4815-8ccf-abdb5fab08d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_windows(amplitudes, window_size=320, window_overlap=160):\n",
    "    windows = {}\n",
    "    windows_labels = {}\n",
    "    for subject_id in amplitudes:\n",
    "        subject_windows = []\n",
    "        subject_windows_labels = []\n",
    "        for activity_id in amplitudes[subject_id]:\n",
    "            activity_amplitudes = amplitudes[subject_id][activity_id].T\n",
    "\n",
    "            n = activity_amplitudes.shape[1] // window_overlap\n",
    "            for i in range(0, (n-1) * window_overlap, window_overlap):\n",
    "                if i+window_size > activity_amplitudes.shape[1]:\n",
    "                    break\n",
    "                subject_windows.append(activity_amplitudes[:,i:i+window_size])\n",
    "                subject_windows_labels.append(ACTIVITY_MAPPING[activity_id])\n",
    "\n",
    "        windows[subject_id] = np.array(subject_windows)\n",
    "        windows_labels[subject_id] = np.array(subject_windows_labels)\n",
    "    return windows, windows_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f5628-d506-4820-abf5-811819bda31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_windows(windows):\n",
    "    proc_windows = {}\n",
    "    with alive_bar(len(windows.keys()), title=f'Processing subject\\'s windows', force_tty=True) as progress_bar:\n",
    "        for subject_id in windows:\n",
    "            windows_copy = copy.deepcopy(windows[subject_id])\n",
    "            for i in range(len(windows_copy)):\n",
    "                windows_copy[i] = np.apply_along_axis(lambda x: wavelet_filtering(dbscan_filtering(x)),1, windows_copy[i])\n",
    "            proc_windows[subject_id] = windows_copy\n",
    "            progress_bar()\n",
    "    return proc_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1838a531-1468-413b-a9b9-ab3691871feb",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d9da5-4a1e-4c53-8877-37ee228eb3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    clear_backend_and_seeds()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(filters=8, kernel_size=(3,10), input_shape=(90, 320, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(filters=8, kernel_size=(3,10)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19816cd7-f6b8-4235-94e2-0fb03d33e741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_executions(execution_windows, windows_labels):\n",
    "    x = np.vstack([ window for window in execution_windows.values() ])\n",
    "    y = np.concatenate([ window_labels for window_labels in windows_labels.values() ])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d0652-96dc-40c2-a67f-59d5af9c5f2a",
   "metadata": {},
   "source": [
    "## E1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec993ad0-8eb3-44e5-bc9e-e1d7947b368d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data loading\n",
    "\n",
    "Follow the instructions provided in [`01_DATA/02_MULTI-ENV/README.md`](./01_DATA/02_MULTI-ENV/README.md) and then execute the following cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba2c9d-83c8-46db-aba9-4ef8afab076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(ENV1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e49fcb-79c3-42f3-9abd-dc991b33b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = amplitude_from_raw_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7411a50e-c6e8-4ec6-aab9-fbb4e9e0b6c7",
   "metadata": {},
   "source": [
    "### Data windowing and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f87ad3-418b-4332-b0f1-88d88a82e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows, windows_labels = create_windows(amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54622f-b18a-4e5c-a9d6-095e42a6c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_windows = process_windows(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a55a3-fc83-4a74-bcd2-0c53d99807df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = combine_executions(proc_windows, windows_labels)\n",
    "y = one_hot_encoding(y, MAPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825b0c11-4535-4e17-acbe-b3d2e684c617",
   "metadata": {},
   "source": [
    "**Free resources**: keep only **x** and **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834c600-c9ab-4a9a-bd34-7aba508f9155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del data\n",
    "del amplitudes\n",
    "del windows\n",
    "del proc_windows\n",
    "del windows_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24eb59e-edfc-478c-bbef-df2c6de1fb47",
   "metadata": {},
   "source": [
    "### 10-fold cross validation\n",
    "\n",
    "The cell below performs the cross validation using the E1 dataset. \n",
    "\n",
    "> **WARNING**: Its execution can last several hours. You can instead load the results obtained by us in [Section 1.6](#summary-multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03828856-76d6-4e56-83c7-30a1d8d6e5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e1_reports = cross_validation(build_model, x, y, folds=FOLDS, batch_size=BATCH_SIZE, epochs=EPOCHS, labels=MULTI_ENV_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170162f2-0e6c-478b-85d5-816549047de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(e1_reports, MULTI_ENV_REPORTS.format('e1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5d992-f2d1-452b-9c0a-750d5dd93252",
   "metadata": {},
   "source": [
    "## E2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd42461-b342-4cfd-9481-3bb6caefd5aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data loading\n",
    "\n",
    "Follow the instructions provided in [`01_DATA/02_MULTI-ENV/README.md`](./01_DATA/02_MULTI-ENV/README.md) and then execute the following cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152b0c8-4760-4e27-9d2c-85cf21b7fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(ENV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52ab74-1ea5-4fb4-bd7e-740b36d413bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = amplitude_from_raw_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf15904-cec0-480e-a0c8-1ac812d15c1d",
   "metadata": {},
   "source": [
    "### Data windowing and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c49616-8353-47b4-bc75-438a907247bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows, windows_labels = create_windows(amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6efc03-1d11-43d1-9da1-5b05a3d69304",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_windows = process_windows(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfc4f8-dd22-43f1-87d7-7d08132e9771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = combine_executions(proc_windows, windows_labels)\n",
    "y = one_hot_encoding(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a22907-d24b-499e-b30b-660d3c9edbb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Free resources**: keep only **x** and **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee326e-1a26-4067-a350-fb3d782f3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del amplitudes\n",
    "del windows\n",
    "del proc_windows\n",
    "del windows_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d7da2-6172-47b6-846d-81474729114a",
   "metadata": {},
   "source": [
    "### 10-fold cross validation\n",
    "\n",
    "The cell below performs the cross validation using the E2 dataset. \n",
    "\n",
    "> **WARNING**: Its execution can last several hours. You can instead load the results obtained by us in [Section 1.6](#summary-multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b76456-2381-48de-815f-fa998c43b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2_reports = cross_validation(build_model, x, y, folds=FOLDS, batch_size=BATCH_SIZE, epochs=EPOCHS, labels=MULTI_ENV_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc273d-c598-465b-ac07-778dee3cc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(e2_reports, MULTI_ENV_REPORTS.format('e2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d34f5-c49e-4e6f-99e3-cb65da546a25",
   "metadata": {},
   "source": [
    "<a id='summary-multi'></a>\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd939aa-7288-4d41-a3dc-f4f350f405ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e1_reports = load_json(MULTI_ENV_REPORTS.format('e1'))\n",
    "e2_reports = load_json(MULTI_ENV_REPORTS.format('e2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0c0964-de60-423c-8c2e-632c5e3b85ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multi-env E1 CV</th>\n",
       "      <td>0.878047</td>\n",
       "      <td>0.885003</td>\n",
       "      <td>0.878047</td>\n",
       "      <td>0.878841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-env E2 CV</th>\n",
       "      <td>0.839214</td>\n",
       "      <td>0.843040</td>\n",
       "      <td>0.839214</td>\n",
       "      <td>0.830280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  precision    recall  f1-score\n",
       "Multi-env E1 CV  0.878047   0.885003  0.878047  0.878841\n",
       "Multi-env E2 CV  0.839214   0.843040  0.839214  0.830280"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_summary([e1_reports, e2_reports], ['Multi-env E1 CV', 'Multi-env E2 CV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2a308-22ab-4f8a-8228-e37a89032c0c",
   "metadata": {},
   "source": [
    "The information presented in the above table corresponds to the one included in the **Table III** (Multi-environment (E1/E2) > This work) of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018d54f-cc8b-45f1-8a17-8f2fff3b344d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310-gpu",
   "language": "python",
   "name": "tf310-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
